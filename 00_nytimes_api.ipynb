{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NYTimes API\n",
    "- This notebook contains the code for retrieving and parsing the New York Times archive headlines over a period of time and exports it as \n",
    "- The code is adapted and modified from [Brienna Herold](https://brienna.medium.com/)'s amazing [article](https://towardsdatascience.com/collecting-data-from-the-new-york-times-over-any-period-of-time-3e365504004)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint as pp\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import dateutil\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm behind a proxy so had to include this. Set this to None by default\n",
    "# proxies = {\n",
    "#    'http': os.environ[\"http_proxy\"],\n",
    "#    'https': os.environ[\"https_proxy\"],\n",
    "# }\n",
    "\n",
    "# set your own NYT Developer's API key\n",
    "API = os.environ[\"NYT_dev_API\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from https://gist.github.com/brienna/bbb381e84649a55ce1c8647665943e3b\n",
    "\n",
    "def send_request(date):\n",
    "    '''Sends a request to the NYT Archive API for given year-month.'''\n",
    "    base_url = 'https://api.nytimes.com/svc/archive/v1'\n",
    "    # date[0] -> year | date[1] -> month\n",
    "    url = base_url + '/' + date[0] + '/' + date[1] + '.json?api-key=' + API # make sure to change the API key\n",
    "    print(f\"Retrieving response from {url.replace(API, '$API_KEY')}\")\n",
    "    response = requests.get(url, proxies=None).json() # set proxy if needed\n",
    "\n",
    "    # we need to make sure we don't exceed the limit of 10 requests/min\n",
    "    #   (note that there's also 4000 requests / day limit)\n",
    "    print(\"Sleep for 20 secs...\")\n",
    "    time.sleep(20)\n",
    "    print(\"Resuming parsing...\")\n",
    "    return response\n",
    "\n",
    "def is_valid(article, date):\n",
    "    '''An article is only worth checking if it is in range, and has a headline.'''\n",
    "    is_in_range = date > start and date < end\n",
    "    has_headline = type(article['headline']) == dict and 'main' in article['headline'].keys()\n",
    "    return is_in_range and has_headline\n",
    "\n",
    "def parse_response(response):\n",
    "    '''Parses and returns response as pandas data frame.'''\n",
    "    print(\"Parsing response...\")\n",
    "    data = {'headline': [],  \n",
    "        'date': [], \n",
    "        'doc_type': [],\n",
    "        'material_type': [],\n",
    "        'section': [],\n",
    "        'keywords': []}\n",
    "    \n",
    "    articles = response['response']['docs'] \n",
    "    for article in articles: # For each article, make sure it falls within our date range\n",
    "        date = dateutil.parser.parse(article['pub_date']).date()\n",
    "        if is_valid(article, date):\n",
    "            data['date'].append(date)\n",
    "            data['headline'].append(article['headline']['main']) \n",
    "            if 'section' in article:\n",
    "                data['section'].append(article['section_name'])\n",
    "            else:\n",
    "                data['section'].append(None)\n",
    "            data['doc_type'].append(article['document_type'])\n",
    "            if 'type_of_material' in article: \n",
    "                data['material_type'].append(article['type_of_material'])\n",
    "            else:\n",
    "                data['material_type'].append(None)\n",
    "            keywords = [keyword['value'] for keyword in article['keywords'] if keyword['name'] == 'subject']\n",
    "            data['keywords'].append(keywords)\n",
    "    return pd.DataFrame(data) \n",
    "\n",
    "def get_data(dates):\n",
    "    '''Sends and parses request/response to/from NYT Archive API for given dates.'''\n",
    "    total = 0\n",
    "    print('Date range: ' + str(dates[0]) + ' to ' + str(dates[-1]))\n",
    "    if not os.path.exists('headlines'):\n",
    "        os.mkdir('headlines')\n",
    "    df_headlines = pd.read_csv(\"headlines/2020-5_2022-8_NYtimes_headlines.csv\")\n",
    "    for date in dates:\n",
    "        response = send_request(date)\n",
    "        df = parse_response(response)\n",
    "        total += len(df)\n",
    "        print(\"Concatenating headlines...\")\n",
    "        df_headlines = pd.concat([df_headlines, df])\n",
    "        print('Saving current data to \"headlines/' + dates[0][0] + '-' + dates[0][1] + '_' + dates[-1][0] + '-' + dates[-1][1] + '_NYtimes_headlines.csv\"...')\n",
    "        print(f\"Headlines retrieved for {date[0]}/{date[1]}.\")\n",
    "        print()\n",
    "        df_headlines.to_csv('headlines/' + dates[0][0] + '-' + dates[0][1] + '_' + dates[-1][0] + '-' + dates[-1][1] + '_NYtimes_headlines.csv', index=False)\n",
    "    print('Number of articles collected: ' + str(len(df_headlines)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.date(2022,8,1)\n",
    "start = end - relativedelta(years=3)\n",
    "\n",
    "months_in_range = [x.split(' ') for x in pd.date_range(start, end, freq='MS').strftime(\"%Y %-m\").tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: ['2021', '6'] to ['2022', '8']\n",
      "Retrieving response from https://api.nytimes.com/svc/archive/v1/2021/6.json?api-key=$API_KEY\n",
      "Sleep for 20 secs...\n",
      "Resuming parsing...\n",
      "Parsing response...\n",
      "Concatenating headlines...\n",
      "Headlines retrieved for 2021/6.\n",
      "\n",
      "Saving current data to \"headlines/2021-6_2022-8_NYtimes_headlines.csv\"...\n",
      "Retrieving response from https://api.nytimes.com/svc/archive/v1/2021/7.json?api-key=$API_KEY\n",
      "Sleep for 20 secs...\n",
      "Resuming parsing...\n",
      "Parsing response...\n",
      "Concatenating headlines...\n",
      "Headlines retrieved for 2021/7.\n",
      "\n",
      "Saving current data to \"headlines/2021-6_2022-8_NYtimes_headlines.csv\"...\n",
      "Retrieving response from https://api.nytimes.com/svc/archive/v1/2021/8.json?api-key=$API_KEY\n",
      "Sleep for 20 secs...\n",
      "Resuming parsing...\n",
      "Parsing response...\n",
      "Concatenating headlines...\n",
      "Headlines retrieved for 2021/8.\n",
      "\n",
      "Saving current data to \"headlines/2021-6_2022-8_NYtimes_headlines.csv\"...\n",
      "Retrieving response from https://api.nytimes.com/svc/archive/v1/2021/9.json?api-key=$API_KEY\n",
      "Sleep for 20 secs...\n",
      "Resuming parsing...\n",
      "Parsing response...\n",
      "Concatenating headlines...\n",
      "Headlines retrieved for 2021/9.\n",
      "\n",
      "Saving current data to \"headlines/2021-6_2022-8_NYtimes_headlines.csv\"...\n",
      "Retrieving response from https://api.nytimes.com/svc/archive/v1/2021/10.json?api-key=$API_KEY\n",
      "Sleep for 20 secs...\n",
      "Resuming parsing...\n",
      "Parsing response...\n",
      "Concatenating headlines...\n",
      "Headlines retrieved for 2021/10.\n",
      "\n",
      "Saving current data to \"headlines/2021-6_2022-8_NYtimes_headlines.csv\"...\n",
      "Retrieving response from https://api.nytimes.com/svc/archive/v1/2021/11.json?api-key=$API_KEY\n",
      "Sleep for 20 secs...\n",
      "Resuming parsing...\n",
      "Parsing response...\n",
      "Concatenating headlines...\n",
      "Headlines retrieved for 2021/11.\n",
      "\n",
      "Saving current data to \"headlines/2021-6_2022-8_NYtimes_headlines.csv\"...\n",
      "Retrieving response from https://api.nytimes.com/svc/archive/v1/2021/12.json?api-key=$API_KEY\n",
      "Sleep for 20 secs...\n",
      "Resuming parsing...\n",
      "Parsing response...\n",
      "Concatenating headlines...\n",
      "Headlines retrieved for 2021/12.\n",
      "\n",
      "Saving current data to \"headlines/2021-6_2022-8_NYtimes_headlines.csv\"...\n",
      "Retrieving response from https://api.nytimes.com/svc/archive/v1/2022/1.json?api-key=$API_KEY\n",
      "Sleep for 20 secs...\n",
      "Resuming parsing...\n",
      "Parsing response...\n",
      "Concatenating headlines...\n",
      "Headlines retrieved for 2022/1.\n",
      "\n",
      "Saving current data to \"headlines/2021-6_2022-8_NYtimes_headlines.csv\"...\n",
      "Retrieving response from https://api.nytimes.com/svc/archive/v1/2022/2.json?api-key=$API_KEY\n",
      "Sleep for 20 secs...\n",
      "Resuming parsing...\n",
      "Parsing response...\n",
      "Concatenating headlines...\n",
      "Headlines retrieved for 2022/2.\n",
      "\n",
      "Saving current data to \"headlines/2021-6_2022-8_NYtimes_headlines.csv\"...\n",
      "Retrieving response from https://api.nytimes.com/svc/archive/v1/2022/3.json?api-key=$API_KEY\n",
      "Sleep for 20 secs...\n",
      "Resuming parsing...\n",
      "Parsing response...\n",
      "Concatenating headlines...\n",
      "Headlines retrieved for 2022/3.\n",
      "\n",
      "Saving current data to \"headlines/2021-6_2022-8_NYtimes_headlines.csv\"...\n",
      "Retrieving response from https://api.nytimes.com/svc/archive/v1/2022/4.json?api-key=$API_KEY\n",
      "Sleep for 20 secs...\n",
      "Resuming parsing...\n",
      "Parsing response...\n",
      "Concatenating headlines...\n",
      "Headlines retrieved for 2022/4.\n",
      "\n",
      "Saving current data to \"headlines/2021-6_2022-8_NYtimes_headlines.csv\"...\n",
      "Retrieving response from https://api.nytimes.com/svc/archive/v1/2022/5.json?api-key=$API_KEY\n",
      "Sleep for 20 secs...\n",
      "Resuming parsing...\n",
      "Parsing response...\n",
      "Concatenating headlines...\n",
      "Headlines retrieved for 2022/5.\n",
      "\n",
      "Saving current data to \"headlines/2021-6_2022-8_NYtimes_headlines.csv\"...\n",
      "Retrieving response from https://api.nytimes.com/svc/archive/v1/2022/6.json?api-key=$API_KEY\n",
      "Sleep for 20 secs...\n",
      "Resuming parsing...\n",
      "Parsing response...\n",
      "Concatenating headlines...\n",
      "Headlines retrieved for 2022/6.\n",
      "\n",
      "Saving current data to \"headlines/2021-6_2022-8_NYtimes_headlines.csv\"...\n",
      "Retrieving response from https://api.nytimes.com/svc/archive/v1/2022/7.json?api-key=$API_KEY\n",
      "Sleep for 20 secs...\n",
      "Resuming parsing...\n",
      "Parsing response...\n",
      "Concatenating headlines...\n",
      "Headlines retrieved for 2022/7.\n",
      "\n",
      "Saving current data to \"headlines/2021-6_2022-8_NYtimes_headlines.csv\"...\n",
      "Retrieving response from https://api.nytimes.com/svc/archive/v1/2022/8.json?api-key=$API_KEY\n",
      "Sleep for 20 secs...\n",
      "Resuming parsing...\n",
      "Parsing response...\n",
      "Concatenating headlines...\n",
      "Headlines retrieved for 2022/8.\n",
      "\n",
      "Saving current data to \"headlines/2021-6_2022-8_NYtimes_headlines.csv\"...\n",
      "Number of articles collected: 58115\n"
     ]
    }
   ],
   "source": [
    "get_data(months_in_range)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('newsgroup_topic')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea367b4c8027123eb5cf9d35911128711d4f91faac60e8e96286a1dd20a400a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
